{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 성능평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- metrixs 서브패키지\n",
    "- confusion_matrix(answer , prediction)\n",
    "- accuracy_score()\n",
    "- precision_score()\n",
    "- recall_score()\n",
    "- f1_score()\n",
    "- classification_report()\n",
    "- roc_curve()\n",
    "- auc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
    "y_pred = [0, 1, 1, 1, 1, 0, 1, 0, 1, 0]\n",
    "\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    TP = TN =FP =FN =0\n",
    "    # TP \n",
    "    if y_test[i] == 1 and y_pred[i] == 1:\n",
    "        tp += 1 \n",
    "    # TN \n",
    "    if y_test[i] == 0 and y_pred[i] == 0:\n",
    "        tn += 1 \n",
    "    # FP \n",
    "    if y_test[i] == 0 and y_pred[i] == 1:\n",
    "        fp += 1 \n",
    "    # FN \n",
    "    if y_test[i] == 1 and y_pred[i] == 0:\n",
    "        fn += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "(TP+TN)/(TP+TN+FP+FN)\n",
    "# Recall - 재현율\n",
    "(TP)/(TP+FN)\n",
    "# Precision - 정밀도\n",
    "(TP)/(TP+FP)\n",
    "#F1 score -> 조화평균..?\n",
    "2*(precision*recall)/(precision+recall)\n",
    "\n",
    "# Fall out(위 양성율) - 값이 낮아야 좋은 모형\n",
    "# 실제 양성클래스에 속하지 않는 표본 중에 양성클래스에 속한다고 예측한 표본의 비율\n",
    "# EX) 거래 - 실제 정상거래인데 사기 거래 예측한 거래의 비율(False Positive Rate)\n",
    "(FP)/(FP+TN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = [2,0,2,2,0,1]\n",
    "y_pred = [0,0,2,2,0,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 분류결과표\n",
    "confusion_matrix(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이진 분류표\n",
    "# 제품을 생산하는 제조공장에서 품질 테스트를 실시하여 불량품을 찾아내고 \n",
    "# 불량품을 공장으로 돌려보낸다(recall)\n",
    "# 품질 테스트의 결과가 양성 -> 불량품 예측한 것이고\n",
    "# 품질 테스트의 결과가 음성 -> 정상 제품 의미\n",
    "\n",
    "# TP : 불량품을 불량품으로 정확하게 예측\n",
    "# TN : 정상제품을 정상상품으로 정확하게 예측\n",
    "# FP : 정상제품을 불량품으로 잘못 예측\n",
    "# FN : 불량품을 정상제품이라고 잘못 예측\n",
    "\n",
    "                #사기예측             #사기예측 x\n",
    "\n",
    "# 불량품을         TP                     FN\n",
    "\n",
    "# 정상제품         FP                    TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0],\n",
       "       [1, 3]], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = [1,0,1,1,0,1]\n",
    "y_pred = [0,0,1,1,0,1]\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### fit() 메서드는 아무 것도 수행하지 않고, predict()는 Sex 피처가 1이면 0, 그렇지 않으면 1로 예측하는 단순한 분류기 생성\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # fit 메서드는 아무것도 학습하지 않음\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    # predict 메서드는 단순히 Sex 피처가 1이면 0, 아니면 1로 예측\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros( (X.shape[0],1) )\n",
    "        for i in range(X.shape[0]):\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1 \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = pd.read_csv('./data/titanic_train.csv')\n",
    "titanic.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "886    0\n",
      "887    1\n",
      "888    0\n",
      "889    1\n",
      "890    0\n",
      "Name: Survived, Length: 891, dtype: int64\n",
      "   PassengerId  Pclass                                               Name  \\\n",
      "0            1       3                            Braund, Mr. Owen Harris   \n",
      "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
      "2            3       3                             Heikkinen, Miss. Laina   \n",
      "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
      "4            5       3                           Allen, Mr. William Henry   \n",
      "\n",
      "      Sex   Age  SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
      "0    male  22.0      1      0         A/5 21171   7.2500   NaN        S  \n",
      "1  female  38.0      1      0          PC 17599  71.2833   C85        C  \n",
      "2  female  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3  female  35.0      1      0            113803  53.1000  C123        S  \n",
      "4    male  35.0      0      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "titanic_label= titanic['Survived']\n",
    "print(titanic_label)\n",
    "titanic_feature_df = titanic.drop(['Survived'],axis=1)\n",
    "print(titanic_feature_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Null 처리 함수\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "## 머신러닝에 불필요한 피처 제거\n",
    "def drop_features(df):\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "## Label Encoding 수행\n",
    "def format_features(df):\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "## 앞에서 실행한 Data Preprocessing 함수 호출\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(titanic_feature_df,\n",
    "                                                    titanic_label,\n",
    "                                                   test_size = .2,\n",
    "                                                   random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = MyDummyClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.8212290502793296\n"
     ]
    }
   ],
   "source": [
    "y_pred = dummy_model.predict(X_test)\n",
    "print('accuracy {}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 업무 특성에 따라서 특정지표를 활용해야한다\n",
    "- Recall -> 암, 사기판정 / Precision(정밀도) -> 스팸메일 분류\n",
    "- recall_score()/precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_eval(y_test,y_pred):\n",
    "    confusion = confusion_matrix(y_test,y_pred)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    print()\n",
    "    print(confusion)\n",
    "    print('*'*50)\n",
    "    print()\n",
    "    print('정확도 : {} , 정밀도 : {} , 재현율 : {}'.format(accuracy,precision,recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[101  16]\n",
      " [ 15  47]]\n",
      "**************************************************\n",
      "\n",
      "정확도 : 0.8268156424581006 , 정밀도 : 0.746031746031746 , 재현율 : 0.7580645161290323\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 로지스틱 회귀\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train,y_train)\n",
    "prediction = lr_model.predict(X_test)\n",
    "display_eval(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :  0.8268156424581006\n",
      "recall :  0.7580645161290323\n",
      "precision :  0.746031746031746\n"
     ]
    }
   ],
   "source": [
    "print('accuracy : ' , (101+47) / (101+15+16+47))\n",
    "print('recall : ' , (47 / (47+15))) # 47 -> TP 101 -> TF\n",
    "print('precision : ' , (47 / (47+16)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [실습] - 유방암 관련 데이터 - 정확, 재현율이 중요하다(실제 P를 N으로 예측하면 안되는경우)\n",
    "# 재현율은 실제 양성을 양성으로 예측한 비율이므로 높을수록 좋은 성능모형이라고 판단 할 수 있다.\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 프레임으로 구조를 변경해서 확인해 보기 \n",
    "\n",
    "cancer_df = pd.DataFrame(data = cancer.data,\n",
    "                        columns=cancer.feature_names)\n",
    "cancer_df['target'] = cancer.target\n",
    "display(cancer_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 분류학습기 생성\n",
    "# # 학습 및 평가(교차 검증)\n",
    "# # 평가지표에 대한 평균값을 구하기\n",
    "\n",
    "# # 랜덤포레스트\n",
    "# rf_clf = RandomForestClassifier()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(cancer_df.iloc[:,:-1],\n",
    "#                                                     cancer_df.loc[:,'target'],\n",
    "#                                                    test_size = .2,\n",
    "#                                                    random_state=11)\n",
    "\n",
    "# # accuracy, precision, recall\n",
    "# rf_clf.fit(X_train,y_train)\n",
    "# prediction = rf_clf.predict(X_test)\n",
    "# display_eval(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 로지스틱\n",
    "# # 랜덤포레스트\n",
    "# lf_clf =  LogisticRegression()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(cancer_df.iloc[:,:-1],\n",
    "#                                                     cancer_df.loc[:,'target'],\n",
    "#                                                    test_size = .2,\n",
    "#                                                    random_state=11)\n",
    "\n",
    "# # accuracy, precision, recall\n",
    "# lf_clf.fit(X_train,y_train)\n",
    "# prediction = lf_clf.predict(X_test)\n",
    "# display_eval(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결정트리\n",
    "# dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(cancer_df.iloc[:,:-1],\n",
    "#                                                     cancer_df.loc[:,'target'],\n",
    "#                                                    test_size = .2,\n",
    "#                                                    random_state=11)\n",
    "\n",
    "# # accuracy, precision, recall\n",
    "# dt_clf.fit(X_train,y_train)\n",
    "# prediction = dt_clf.predict(X_test)\n",
    "# display_eval(y_test, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습기 생성\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# 데이터 분리\n",
    "label=cancer_df['target']\n",
    "features=cancer_df.drop(columns=['target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['fit_time', 'score_time', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1_score'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate , KFold\n",
    "from sklearn.metrics import make_scorer , f1_score\n",
    "\n",
    "# 학습 및 평가 (교차 검증)\n",
    "fold = KFold(n_splits=20 , \n",
    "             random_state=1,\n",
    "             shuffle=True)\n",
    "\n",
    "scoring = {\n",
    "        'accuracy'  :  make_scorer(accuracy_score) ,\n",
    "        'precision' :  make_scorer(precision_score),\n",
    "        'recall'    :  make_scorer(recall_score) , \n",
    "        'f1_score'  :  make_scorer(f1_score)\n",
    " }\n",
    "\n",
    "result = cross_validate(rf_model , features , label , cv=fold , scoring=scoring)\n",
    "\n",
    "print(result.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.96\n",
      "precision 0.97\n",
      "recall 0.97\n",
      "f1_score 0.97\n"
     ]
    }
   ],
   "source": [
    "# 평가지표에 대한 평균값을 구하기\n",
    "print('accuracy',np.round(result['test_accuracy'].mean(),2))\n",
    "print('precision',np.round(result['test_precision'].mean(),2))\n",
    "print('recall',np.round(result['test_recall'].mean(),2))\n",
    "print('f1_score',np.round(result['test_f1_score'].mean(),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'max_features': 8, 'n_estimators': 200}\n",
      "0.9759450171821306\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data,\n",
    "                                                    cancer.target,\n",
    "                                                    test_size=0.2)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=123)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [200, 300],\n",
    "    'max_features' : [8, 10],\n",
    "    'max_depth'    : [4, 6]\n",
    "}\n",
    "\n",
    "\n",
    "Grid_rf = GridSearchCV(random_forest, \n",
    "                       param_grid = params,\n",
    "                       cv         = 3,\n",
    "                       scoring    = 'recall')\n",
    "\n",
    "Grid_rf.fit(X_train, y_train)\n",
    "print(Grid_rf.best_params_)\n",
    "print(Grid_rf.best_score_)\n",
    "\n",
    "# {'max_depth': 4, 'max_features': 8, 'n_estimators': 200}\n",
    "# 0.9669922669922671\n",
    "\n",
    "\n",
    "# test set 예측\n",
    "\n",
    "y_pred = Grid_rf.best_estimator_.predict(X_test)\n",
    "# 모델성능평가 함수\n",
    "def display_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print('accuracy' , accuracy)\n",
    "    print('precision' , precision)\n",
    "    print('recall' , recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9385964912280702\n",
      "precision 0.927536231884058\n",
      "recall 0.9696969696969697\n"
     ]
    }
   ],
   "source": [
    "display_eval(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
